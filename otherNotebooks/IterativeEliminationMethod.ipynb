{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append('../BioExp')\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from BioExp.helpers.metrics import *\n",
    "from BioExp.helpers.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is inspired by IESDS method in game theory, where each and every stratergy fights for its survival. In this approach we generate concepts by clustering the weights in predefined layers of the network.\n",
    "\n",
    "Now at initial step all the concepts are considered are of equal importance, and the relevance matrix is generated. Based on relevance matric one of more concepts are eliminated and the entire process if repeated till convergance.\n",
    "\n",
    "By doing this we end with more robust and more important features responsible for higher dice of classification score.\n",
    "\n",
    "Initial test on Brats with SimUnet model, trained model scores are depected bellow:\n",
    "\n",
    "\n",
    "| Model Type |     WT Dice | TC Dice  | ET Dice|\n",
    "|------------|:------------|:---------|:-------|\n",
    "| DenseUnet  |     0.830   | 0.760    | 0.685  |\n",
    "| ResUnet    |     0.788   | 0.734    | 0.649  |\n",
    "| SimUnet    |     0.743   | 0.693    | 0.523  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pi/miniconda/envs/bioexp/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 240, 240, 1)       0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 240, 240, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 240, 64)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 240, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 240, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 120, 120, 128)     32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 120, 120, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 120, 120, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 60, 256)       131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 512)       524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 60, 60, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 60, 60, 256)       524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 120, 120, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 120, 120, 128)     131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 120, 120, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 120, 120, 128)     147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 240, 240, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 240, 240, 64)      32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 240, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 240, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 240, 240, 64)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 240, 240, 4)       260       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 240, 240, 4)       0         \n",
      "=================================================================\n",
      "Total params: 9,207,748\n",
      "Trainable params: 9,201,988\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model and parameter defn\n",
    "# currently using simple U-net\n",
    "\n",
    "seq_map = {'flair': 0, 't1': 1, 't2': 3, 't1c':2}\n",
    "seq = 'flair'\n",
    "\n",
    "model_path        = '../BioExp/saved_models/model_{}_scaled/model-archi.h5'.format(seq)\n",
    "weights_path      = '../BioExp/saved_models/model_{}_scaled/model-wts-{}.hdf5'.format(seq, seq)\n",
    "\n",
    "layers_to_consider = ['conv2d_2', 'conv2d_3', 'conv2d_4', 'conv2d_5', 'conv2d_6','conv2d_7', 'conv2d_8', 'conv2d_9',\\\n",
    "                      'conv2d_10', 'conv2d_11', 'conv2d_12', 'conv2d_13', 'conv2d_14', 'conv2d_15', 'conv2d_16',\\\n",
    "                       'conv2d_17','conv2d_18', 'conv2d_19', 'conv2d_20', 'conv2d_21']\n",
    "\n",
    "\n",
    "model = load_model(model_path, custom_objects={'gen_dice_loss':gen_dice_loss,\n",
    "                                'dice_whole_metric':dice_whole_metric,\n",
    "                                'dice_core_metric':dice_core_metric,\n",
    "                                'dice_en_metric':dice_en_metric})\n",
    "model.load_weights(weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: BioExp Clustering] Layer: conv2d_2, Nclusters: 3, Labels: [0 1 2], Freq. of each labels: [24, 17, 23]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_3, Nclusters: 4, Labels: [0 1 2 3], Freq. of each labels: [18, 16, 13, 17]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_4, Nclusters: 4, Labels: [0 1 2 3], Freq. of each labels: [55, 38, 23, 12]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_5, Nclusters: 4, Labels: [0 1 2 3], Freq. of each labels: [63, 16, 36, 13]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_6, Nclusters: 4, Labels: [0 1 2 3], Freq. of each labels: [48, 27, 31, 22]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_7, Nclusters: 5, Labels: [0 1 2 3 4], Freq. of each labels: [61, 35, 80, 41, 39]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_8, Nclusters: 5, Labels: [0 1 2 3 4], Freq. of each labels: [103, 58, 30, 45, 20]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_9, Nclusters: 6, Labels: [0 1 2 3 4 5], Freq. of each labels: [79, 49, 63, 16, 22, 27]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_10, Nclusters: 6, Labels: [0 1 2 3 4 5], Freq. of each labels: [76, 130, 148, 76, 53, 29]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_11, Nclusters: 4, Labels: [0 1 2 3], Freq. of each labels: [221, 107, 104, 80]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_12, Nclusters: 7, Labels: [0 1 2 3 4 5 6], Freq. of each labels: [118, 73, 93, 85, 48, 60, 35]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_13, Nclusters: 5, Labels: [0 1 2 3 4], Freq. of each labels: [65, 72, 53, 38, 28]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_14, Nclusters: 6, Labels: [0 1 2 3 4 5], Freq. of each labels: [71, 42, 35, 33, 36, 39]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_15, Nclusters: 6, Labels: [0 1 2 3 4 5], Freq. of each labels: [43, 88, 41, 32, 34, 18]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_16, Nclusters: 5, Labels: [0 1 2 3 4], Freq. of each labels: [33, 29, 29, 26, 11]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_17, Nclusters: 3, Labels: [0 1 2], Freq. of each labels: [72, 25, 31]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_18, Nclusters: 6, Labels: [0 1 2 3 4 5], Freq. of each labels: [47, 24, 22, 16, 11, 8]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_19, Nclusters: 5, Labels: [0 1 2 3 4], Freq. of each labels: [23, 10, 17, 8, 6]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_20, Nclusters: 6, Labels: [0 1 2 3 4 5], Freq. of each labels: [17, 12, 10, 11, 8, 6]\n",
      "[INFO: BioExp Clustering] Layer: conv2d_21, Nclusters: 3, Labels: [0 1 2], Freq. of each labels: [43, 15, 6]\n"
     ]
    }
   ],
   "source": [
    "from BioExp.clusters import clusters\n",
    "\n",
    "concept_info = []\n",
    "node = 0\n",
    "\n",
    "save_root = './Logs/DiceGraphs/{}/weights_cluster/'.format(seq)\n",
    "for layer_name in layers_to_consider:\n",
    "    save_path = os.path.join(save_root, layer_name)\n",
    "    os.makedirs(save_path, exist_ok = True)\n",
    "    \n",
    "    C = clusters.Cluster(model, weights_path, layer_name)\n",
    "    labels = C.get_clusters(threshold = 0.5, save_path=save_path)\n",
    "    C.plot_weights(labels, os.path.join(save_path, 'wt-samples'))\n",
    "    \n",
    "    for label in np.unique(labels):\n",
    "        nodename = 'node_{}'.format(node)\n",
    "        layername = layer_name\n",
    "        fidxs = np.where(labels==label)[0]\n",
    "        info = {'concept_name': nodename, \n",
    "                  'layer_name': layername, \n",
    "                 'filter_idxs': fidxs}\n",
    "        concept_info.append(info)\n",
    "        node += 1\n",
    "        \n",
    "with open(os.path.join(save_root, 'cluster_info.cpickle'), 'wb') as file:\n",
    "    pickle.dump(concept_info, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Delta Graph\n",
    "\n",
    "$$AM[C^p_i, C^q_j] = \\mathbb{E}_{(x, gt)\\sim Data} \\left (DICE(~ \\Phi(x), GT) - DICE(~ \\Phi(x ~|~~ do(C^p_i = 0), ~~do(C^q_j = 0)), GT) \\right)$$\n",
    "\n",
    "This is an idea to estimate the importance of two concepts by interventional probability, i.e. finding the effect of pair of concepts by calculating dice difference with and without those pairs of concepts. In the above equation the importance of concepts $C^p_i$ and $C^q_j$ are obtained by calculating difference in dice with and without them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BioExp.helpers import utils\n",
    "from BioExp.graphs import delta\n",
    "\n",
    "metric = dice_label_coef # defined in BioExp.helpers.metrics\n",
    "\n",
    "def dataloader(nslice = 78):\n",
    "    def loader(img_path, mask_path):\n",
    "        image, gt =  utils.load_vol_brats(img_path, slicen=nslice)\n",
    "        return image[:,:, seq_map[seq]][:,:, None], gt\n",
    "    return loader\n",
    "\n",
    "data_root_path = '../BioExp/sample_vol/brats/'\n",
    "\n",
    "infoclasses = {}\n",
    "# for i in range(4): infoclasses['class_'+str(i)] = (i,)\n",
    "infoclasses['whole'] = (1,2,3,)\n",
    "infoclasses['ET'] = (3,)\n",
    "infoclasses['CT'] = (1,3,)\n",
    "\n",
    "G = delta.DeltaGraph(model, weights_path, metric, classinfo = infoclasses)\n",
    "\n",
    "save_root = './Logs/DiceGraphs/{}/weights_cluster/'.format(seq)\n",
    "with open(os.path.join(save_root, 'cluster_info.cpickle'), 'rb') as file:\n",
    "    concepts_info = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate graph AM\n",
    "save_path =  './Logs/DiceGraphs/{}'.format(seq)\n",
    "AM = G.generate_graph(concepts_info, \n",
    "                 dataset_path = data_root_path, \n",
    "                 loader = dataloader(), \n",
    "                 save_path = save_path)\n",
    "\n",
    "save_root = './Logs/DiceGraphs/{}/'.format(seq)\n",
    "with open(os.path.join(save_root, 'Graph_AMs.cpickle'), 'wb') as file:\n",
    "    pickle.dump(AM, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "save_root = './Logs/DiceGraphs/{}/'.format(seq)\n",
    "with open(os.path.join(save_root, 'Graph_AMs.cpickle'), 'rb') as file:\n",
    "    AM = pickle.load(file)\n",
    "\n",
    "for class_ in infoclasses.keys():\n",
    "    print (\"========{}=======\".format(class_))\n",
    "    plt.clf()\n",
    "    plt.imshow(AM[class_], cmap ='jet', vmin = 0, vmax = 1)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(save_root, class_+'.png'), dpi=2000, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "significance = G.node_significance(concepts_info, dataset_path = data_root_path, loader = dataloader(), save_path = save_root)\n",
    "pprint(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modify concepts info\n",
    "new_nodes = []\n",
    "T = 0.1\n",
    "class_ = 'whole'\n",
    "M = np.array(AM[class_])\n",
    "\n",
    "for nx in range(M.shape[0]):\n",
    "    for ny in range(nx):\n",
    "        if M[nx, ny] < T: continue\n",
    "        elif M[nx, ny] > T:\n",
    "            if (M[nx, nx] > T) or (M[ny, ny] > T):\n",
    "                if M[nx, nx] > T:\n",
    "                    new_nodes.append(nx)\n",
    "                if M[ny, ny] > T:\n",
    "                    new_nodes.append(ny)\n",
    "            \n",
    "\n",
    "new_nodes = np.sort(np.unique(new_nodes))\n",
    "print (np.array(AM[class_])[:, new_nodes][new_nodes, :].shape)\n",
    "for class_ in infoclasses.keys():\n",
    "    print (\"========{}=======\".format(class_))\n",
    "    plt.clf()\n",
    "    plt.imshow(np.array(AM[class_])[:, new_nodes][new_nodes, :], cmap ='jet', vmin = 0, vmax = 1)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(save_root, 'modified_' +class_+'.png'), dpi=2000, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
